{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [27/Feb/2025 01:42:46] \"OPTIONS /summarize HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received Data: {'video_url': 'https://youtu.be/-bt_y4Loofg?feature=shared', 'lang': 'en'}\n",
      "Target Language: en\n",
      "[youtube] Extracting URL: https://youtu.be/-bt_y4Loofg?feature=shared\n",
      "[youtube] -bt_y4Loofg: Downloading webpage\n",
      "[youtube] -bt_y4Loofg: Downloading ios player API JSON\n",
      "[youtube] -bt_y4Loofg: Downloading mweb player API JSON\n",
      "[youtube] -bt_y4Loofg: Downloading player c548b3da\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/c548b3da/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] -bt_y4Loofg: nsig extraction failed: Some formats may be missing\n",
      "         n = y9cEl-G__AcmIXmY ; player = https://www.youtube.com/s/player/c548b3da/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/c548b3da/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] -bt_y4Loofg: nsig extraction failed: Some formats may be missing\n",
      "         n = HCufakJvuxwa57u4 ; player = https://www.youtube.com/s/player/c548b3da/player_ias.vflset/en_US/base.js\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] -bt_y4Loofg: Downloading m3u8 information\n",
      "[info] -bt_y4Loofg: Downloading 1 format(s): 251\n",
      "[download] Destination: downloaded_audio\n",
      "[download] 100% of    2.60MiB in 00:00:05 at 491.17KiB/s \n",
      "[ExtractAudio] Destination: downloaded_audio.wav\n",
      "Deleting original file downloaded_audio (pass -k to keep)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VICTUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:509: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "127.0.0.1 - - [27/Feb/2025 01:44:51] \"POST /summarize HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation Error: 'TranslationPipeline' object has no attribute 'translate'\n",
      "Translation Error: 'TranslationPipeline' object has no attribute 'translate'\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from transformers import pipeline\n",
    "from flask_cors import CORS\n",
    "from pydub import AudioSegment\n",
    "import yt_dlp\n",
    "import torch\n",
    "import os\n",
    "import spacy\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict, Counter\n",
    "from IPython.display import display, Image\n",
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# Initialize device and pipelines\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# Initialize translation pipeline (Change 'Helsinki-NLP/opus-mt-en-fr' to the desired language pair)\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "\n",
    "asr_pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=\"openai/whisper-base\",\n",
    "    chunk_length_s=30,\n",
    "    device=device,\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "summarizer = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"sshleifer/distilbart-cnn-12-6\",\n",
    "    device=device,\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "# Load NLP model for keyword extraction\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def download_audio(video_url):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio',\n",
    "        'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'wav'}],\n",
    "        'outtmpl': 'downloaded_audio'\n",
    "    }\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])\n",
    "\n",
    "def split_audio_into_chunks(audio_file_path, chunk_length_ms=60000):\n",
    "    audio = AudioSegment.from_wav(audio_file_path)\n",
    "    total_length = len(audio)\n",
    "    chunks = []\n",
    "    for start in range(0, total_length, chunk_length_ms):\n",
    "        chunk = audio[start:start + chunk_length_ms]\n",
    "        chunk_path = f\"chunk_{start // chunk_length_ms}.wav\"\n",
    "        chunk.export(chunk_path, format=\"wav\")\n",
    "        chunks.append(chunk_path)\n",
    "    return chunks\n",
    "\n",
    "def dynamic_tokenizer_kwargs(input_length):\n",
    "    max_length = min(1024, max(10, input_length // 2))\n",
    "    min_length = max(10, input_length // 4)\n",
    "    return {'truncation': True, 'max_length': max_length, 'min_length': min_length}\n",
    "\n",
    "def process_audio_chunks(audio_chunks):\n",
    "    texts = [asr_pipe(chunk)[\"text\"] for chunk in audio_chunks]\n",
    "    summaries = []\n",
    "    for text in texts:\n",
    "        input_length = len(text.split())\n",
    "        tokenizer_kwargs = dynamic_tokenizer_kwargs(input_length)\n",
    "        summary = summarizer(text, do_sample=False, **tokenizer_kwargs)\n",
    "        summaries.append(summary[0]['summary_text'])\n",
    "    return summaries\n",
    "\n",
    "def generate_mind_map(summary_text):\n",
    "    doc = nlp(summary_text)\n",
    "    nodes = []\n",
    "    links = []\n",
    "    keyword_map = defaultdict(set)\n",
    "    \n",
    "    main_topics = set()\n",
    "    \n",
    "    # Extract key topics and relationships\n",
    "    for token in doc:\n",
    "        if token.pos_ in [\"NOUN\", \"PROPN\"]:  # Focus on nouns & proper nouns\n",
    "            parent = token.head.text\n",
    "            if parent != token.text:  # Avoid self-links\n",
    "                keyword_map[parent].add(token.text)\n",
    "                main_topics.add(parent)\n",
    "\n",
    "    # Build nodes and links\n",
    "    seen_nodes = set()\n",
    "    for main_topic in main_topics:\n",
    "        main_id = f\"node-{main_topic}\"\n",
    "        if main_id not in seen_nodes:\n",
    "            nodes.append({\"id\": main_id, \"name\": main_topic, \"type\": \"heading\"})\n",
    "            seen_nodes.add(main_id)\n",
    "\n",
    "        for sub in keyword_map[main_topic]:\n",
    "            sub_id = f\"node-{sub}\"\n",
    "            if sub_id not in seen_nodes:\n",
    "                nodes.append({\"id\": sub_id, \"name\": sub, \"type\": \"subtopic\"})\n",
    "                seen_nodes.add(sub_id)\n",
    "            links.append({\"source\": main_id, \"target\": sub_id})\n",
    "\n",
    "    return {\"nodes\": nodes, \"links\": links}\n",
    "\n",
    "def extract_topic(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract nouns and proper nouns\n",
    "    words = [token.text for token in doc if token.pos_ in [\"NOUN\", \"PROPN\"] and not token.is_stop]\n",
    "\n",
    "    # Count occurrences of each noun\n",
    "    word_freq = Counter(words)\n",
    "\n",
    "    # Prioritize words appearing in the first sentence(s)\n",
    "    first_sentences = list(doc.sents)[:2]  # Look at the first two sentences\n",
    "    first_mentions = [token.text for sent in first_sentences for token in sent if token.pos_ in [\"NOUN\", \"PROPN\"]]\n",
    "\n",
    "    # Give extra weight to early mentions\n",
    "    for word in first_mentions:\n",
    "        word_freq[word] += 3  # Boost early mentions\n",
    "\n",
    "    # Select the most frequently mentioned word\n",
    "    main_topic = word_freq.most_common(1)\n",
    "\n",
    "    return main_topic[0][0] if main_topic else \"Unknown Topic\"\n",
    "\n",
    "def extract_sentences(summary):\n",
    "    doc = nlp(summary)\n",
    "    return [sent.text.strip() for sent in doc.sents if sent.text.strip()]\n",
    "\n",
    "def extract_main_topics(text, top_n=10):\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text for ent in doc.ents if ent.label_ in ['ORG', 'PERSON', 'GPE', 'LOC', 'PRODUCT']]\n",
    "    entity_freq = Counter(entities)\n",
    "\n",
    "    if entity_freq:\n",
    "        main_topics = [topic for topic, _ in entity_freq.most_common(top_n)]\n",
    "    else:\n",
    "        words = [token.text for token in doc if token.is_alpha and not token.is_stop]\n",
    "        word_freq = Counter(words)\n",
    "        main_topics = [word for word, _ in word_freq.most_common(top_n)]\n",
    "\n",
    "    return main_topics\n",
    "\n",
    "def find_sentence_relations(keywords, sentences, max_sentences=1):\n",
    "    keyword_sentences = defaultdict(list)\n",
    "    assigned_sentences = set()  # To keep track of assigned sentences\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        for sentence in sentences:\n",
    "            if len(sentence.split()) > 10 and sentence not in assigned_sentences:\n",
    "                if keyword.lower() in sentence.lower():\n",
    "                    if len(keyword_sentences[keyword]) < max_sentences:\n",
    "                        keyword_sentences[keyword].append(sentence)\n",
    "                        assigned_sentences.add(sentence)  # Mark sentence as used\n",
    "                        break  # Stop after assigning the sentence to the keyword\n",
    "    \n",
    "    return keyword_sentences\n",
    "\n",
    "def get_video_title(url):\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    return soup.title.string.replace(\"- YouTube\", \"\").strip()\n",
    "\n",
    "def extract_most_frequent_title_word(title, text):\n",
    "    doc = nlp(text.lower())  # Convert to lowercase for consistency\n",
    "    words = [token.text for token in doc if token.is_alpha and not token.is_stop]  # Remove non-alphabetic words and stop words\n",
    "\n",
    "    # Tokenize title words\n",
    "    title_words = title.lower().split()\n",
    "\n",
    "    # Count occurrences of title words in transcription\n",
    "    word_freq = Counter(words)\n",
    "    common_words = {word: word_freq[word] for word in title_words if word in word_freq}\n",
    "\n",
    "    # Find the most frequent word\n",
    "    return max(common_words, key=common_words.get, default=\"Unknown Title\")\n",
    "\n",
    "outro_patterns = [\n",
    "    r\"thanks for watching\", r\"see you in the next video\", r\"don't forget to subscribe\",\n",
    "    r\"hit the (like|subscribe) button\", r\"leave a comment\", r\"hope you enjoyed\",\n",
    "    r\"follow for more\", r\"stay tuned\", r\"this was all about\", r\"let me know in the comments\",\n",
    "    r\"Welcome to this video\", r\"let's wrap up\", r\"in 100 seconds\", r\"this has been\", r\"for watching\"\n",
    "]\n",
    "\n",
    "def remove_outliers(text):\n",
    "    \"\"\" Removes unwanted sentences that match outro patterns. \"\"\"\n",
    "    sentences = list(nlp(text).sents)  # Segment into sentences\n",
    "    filtered_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_text = sentence.text.strip()\n",
    "        sentence_lower = sentence_text.lower()\n",
    "\n",
    "        # Skip sentences matching engagement/outro phrases\n",
    "        if any(re.search(pattern, sentence_lower) for pattern in outro_patterns):\n",
    "            continue\n",
    "\n",
    "        # Skip very short sentences (likely irrelevant)\n",
    "        if len(sentence_text.split()) < 4:\n",
    "            continue\n",
    "\n",
    "        filtered_sentences.append(sentence_text)\n",
    "\n",
    "    return filtered_sentences\n",
    "\n",
    "def translate_text(text, target_language=\"es\"):\n",
    "    try:\n",
    "        result = translator.translate(text, dest=target_language)\n",
    "        return result.text\n",
    "    except Exception as e:\n",
    "        print(\"Translation Error:\", str(e))\n",
    "        return text  # Return the original text if translation fails\n",
    "\n",
    "\n",
    "@app.route(\"/summarize\", methods=[\"POST\"])\n",
    "def summarize_video():\n",
    "    try:\n",
    "        data = request.get_json()\n",
    "        print(\"Received Data:\", data)\n",
    "        video_url = data.get(\"video_url\")\n",
    "        if not video_url:\n",
    "            return jsonify({\"error\": \"Missing video_url\"}), 400\n",
    "        \n",
    "        target_language = data.get(\"lang\")\n",
    "        if not target_language:\n",
    "            return jsonify({\"error\": \"Missing target language\"}), 400\n",
    "\n",
    "        print(\"Target Language:\", target_language)\n",
    "\n",
    "        download_audio(video_url)\n",
    "        audio_file_path = \"downloaded_audio.wav\"\n",
    "        chunks = split_audio_into_chunks(audio_file_path)\n",
    "\n",
    "        # Store full transcription text\n",
    "        transcription = []\n",
    "\n",
    "        for chunk in chunks:\n",
    "            text = asr_pipe(chunk)[\"text\"]\n",
    "            transcription.append(text)  # Store each chunk\n",
    "        transcription = \" \".join(transcription)  # Join all transcriptions\n",
    "\n",
    "\n",
    "\n",
    "        full_transcription = []\n",
    "\n",
    "        cleaned_sentences = remove_outliers(transcription)\n",
    "\n",
    "        for sent in cleaned_sentences:\n",
    "            full_transcription.append(sent)\n",
    "\n",
    "        full_transcription = \" \".join(full_transcription)\n",
    "\n",
    "\n",
    "        # Summarization\n",
    "        all_summaries = []\n",
    "        for text in full_transcription.split(\"\\n\"):\n",
    "            if text.strip():\n",
    "                input_length = len(text.split())\n",
    "                tokenizer_kwargs = dynamic_tokenizer_kwargs(input_length)\n",
    "                summary = summarizer(text, do_sample=False, **tokenizer_kwargs)\n",
    "                all_summaries.append(summary[0]['summary_text'])\n",
    "\n",
    "        # Cleanup\n",
    "        os.remove(audio_file_path)\n",
    "        for chunk in chunks:\n",
    "            os.remove(chunk)\n",
    "\n",
    "        full_summary = \" \".join(all_summaries)\n",
    "        points = extract_sentences(full_transcription)\n",
    "        text_data = \"\\n\".join(points)\n",
    "\n",
    "        # Extract main topics (keywords)\n",
    "        main_topics = extract_main_topics(text_data)\n",
    "\n",
    "        #central topic finding\n",
    "        video_title = get_video_title(video_url)\n",
    "        most_frequent_word = extract_most_frequent_title_word(video_title, full_transcription)\n",
    "\n",
    "\n",
    "        # Find relationships between keywords and sentences\n",
    "        keyword_sentences = find_sentence_relations(main_topics, points)\n",
    "\n",
    "\n",
    "\n",
    "        translated_summary = translate_text(full_summary, target_language)\n",
    "        translated_transcription = translate_text(text_data, target_language)\n",
    "       \n",
    "\n",
    "        return jsonify({\n",
    "            \"summary\": translated_summary,\n",
    "            \"transcription\": translated_transcription,  # Store the full transcription\n",
    "            \"mind_map\": keyword_sentences,\n",
    "            \"central\": most_frequent_word\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    app.run(port=5000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
